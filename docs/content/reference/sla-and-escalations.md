---
title: SLA & escalations
weight: 40
menu:
  main:
    parent: reference
---
# SLA & Escalations

SLA stands for "Service Level Agreement". Vamp uses it to define a pre-described set of boundaries to a service and the actions that should take place once the service crosses those boundaries. In essence an SLA + its associated escalation is a workflow that is checked and controlled by Vamp based on the runtime behaviour of a service. SLA's and escalations are defined with the VAMP DSL.

## The SLA event system

For each cluster in a blueprint, it's possible to define an SLA. A common example would be to check if the average response time of the cluster (averaged across all services) is higher or lower than a certain threshold. Under the hood, an SLA workflow creates two distinct events. These are are sent from Vamp Core to Vamp Pulse.

* **Escalate** for a specific deployment & cluster: e.g. if the response time is higher than the upper threshold.
* **DeEscalate** for a specific deployment & cluster: e.g. if the response time is lower than the lower threshold.

SLA monitoring is a continuous background process with a configurable interval time. On each run an SLA workflow is executed for each deployment & cluster that has an SLA defined. Within the same SLA definition it's possible to define a list of escalations. Escalations are triggered by escalation events (Escalate/DeEscalate).

This means escalation events can be generated by the third party systems by sending them to Vamp Pulse. This would allow scaling up or down to be triggered by basically any system that can `POST` a piece of JSON.

SLA's are in essence pieces of code inside Vamp that stick to this event model and can use, if they want, the metrics and event data streaming out of Vamp Pulse to make decisions on how things are and should be running.

## SLA types

Vamp currently ships with the following SLA types:

### Response time with sliding window 

The `response_time_sliding_window` SLA triggers events based on response times. This is how you define one with an inline definition in a blueprint:

```yaml
---
name: monarch

endpoints:
  monarch.port: 80

clusters:

  monarch:
    breed:
      name: monarch
      deployable: vamp/monarch
      ports:
        port: 80

    scale:
      cpu: 1
      memory: 1024
      instances: 2

    sla:
      # Type of SLA.
      type: response_time_sliding_window
      threshold:
        upper: 1000   # Upper threshold in milliseconds.
        lower: 100    # Lower threshold in milliseconds.
      window:
        interval: 600 # Time period in seconds used for
                      # average response time aggregation.
        cooldown: 600 # Time period in seconds. During this 
                      # period no new escalation events will 
                      # be generated. New event may be expected 
                      # not before cooldown + interval time has 
                      # been reached after the last event. 
     
      # List of escalations.
      escalations:
        - 
          type: scale_instances
          minimum: 1
          maximum: 3
          scale_by: 1
```          

**Notice** how the SLA is defined separately from the escalations. This is key to how Vamp approaches SLA's and how modular and extendable the system is.

## Escalations

An escalation is a workflow triggered by an escalation event. Vamp checks for these escalation events using a continuous background process with a configurable interval time. If the events match the escalation handlers defined in the DSL, the action is executed.

Again: escalation events can be generated by third party systems and they will be handled in the same manner as events created by Vamp SLA workflows. 

Any escalation that is trigger should be handled by an escalation handler...

### Escalation handlers

Vamp ships with the following set of escalation handlers. These handlers can be composed into intricate escalation systems.

#### scale_instances
Scales up the number of running instances. It is applied only to the first service in the cluster (old or "A" version). You can set upper limits to how far you want to scale out or in, effectively guaranteeing a minimum set of running instances. This is very much like AWS auto-scaling.

```yaml
---
type: scale_instances
target: monarch  # Target cluster for the scale up/down.
                 # If it's not specified, by default it's the 
                 # current cluster where SLA escalations are 
                 # specified.
minimum: 1       # Minimum number of instances.
maximum: 3       # Maximum number of instances.
scale_by: 1      # Increment/decrement to use on current 
                 # number of running instances.
```

#### scale_cpu
Scales up the number of CPUs per instances. It is applied only on the first service in the cluster (old or "A" version).

```yaml
---
type: scale_cpu
target: monarch  
minimum: 1
maximum: 3 
scale_by: 0.5
```

#### scale_memory
Scales up the memory per instance. It is applied only on the first service in the cluster (old or "A" version).

```yaml
---
type: scale_memory
target: monarch  
minimum: 512     # In MB.
maximum: 4096    # In MB.
scale_by: 512    # In MB.
```

### Composing escalation handlers

Vamp has a set of predefined escalation handler types that deal with escalations. You can compose these handlers in the DSL to get the desired outcome of an escalation event. Currently, the following escalation handlers are supported:

#### to_all
This is a "group" escalation handler that contains a list of escalations. On each escalation event it will propagate the escalation to **all** escalation handlers from its list. No order or hierarchy.

```yaml
---
to_all:
  escalations:
    # Scale up/down.
    - scale_instances
    # And notify for each event.
    - notify
```

#### to_one
This is a group escalation handler that contains a list of escalations. On each escalation event it will propagate the escalation to each escalation handler (from its list) until one can handle it. On an `Escalate` event, it will start at the head of the list. During a `DeEscalate` event is will start at the rear.
When is this useful? Well, Vamp could try to scale up the service and if that;s not possible anymore (e.g. reached the upper limit of allowed scale) then an email can be sent.

```yaml
---
to_one:
  escalations:
    # First try to escalate.
    - scale_instances
    # If it's not possible, proceed with notifying.
    - notify
```

A more complex example is:

```yaml
---
name: monarch

endpoints:
  monarch1.port: 80/http

environment_variables:
  monarch2.password: secret

clusters:

  monarch1:
    breed:
      name: monarch1
      deployable: vamp/monarch1
      ports:
        port: 80/http
      environment_variables:
        STORAGE_HOST: $storage.host
        DB_PORT: $storage.ports.port
        STORAGE_PASS: $storage.environment_variables.password
      
      dependencies:
        storage: monarch2

    scale:
      cpu: 1
      memory: 1024
      instances: 1
    
    sla:
      type: response_time_sliding_window
      threshold:
        upper: 1000
        lower: 100
      window:
        interval: 600
        cooldown: 600

      escalations:
        - 
          to_one:
            escalations:
              -
                type: scale_instances
                # First try to scale up storage service.
                target: monarch2
                minimum: 1
                maximum: 3
                scale_by: 1

              -
                type: scale_instances
                # If we cannot scale up storage anymore, scale up this.
                target: monarch1
                minimum: 1
                maximum: 3
                scale_by: 1

  monarch2:
    breed:
      name: monarch2
      deployable: vamp/monarch2
      ports:
        port: 3306
      environment_variables:
        STORAGE_PASS: password
    scale:
      cpu: 1
      memory: 1024
      instances: 1
```
